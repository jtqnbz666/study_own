【内存内漏怎么查：先检查自己是否用了内存池，如果是自己的内存池出现了内存泄漏，添加打印信息来进一步排查，若自己没有使用内存池，则是第三方库的内存池可能出错】

定时器设计：Linux高性能服务器书上的时间轮和0voice的不太一样，书上那种没有体现出定时任务的更新

Linux高性能服务器：只讲了单时间轮，使用了圈数的统计，不方便更新定时器。
0voice：定时器结点中用了一个指针指向一个特殊的结点，因为是指针结点，所以不同的定时器结点内可以指向同一个特殊结点，在这个特殊结点上加了一个used变量，每收到一个keepalive，used++, 一定时间后used-- ，当used为0时，清除连接。这种方式用在判断对方是否正常的应用中。

redis定时器设计是无序的单链表，任务多的时候使用调表
map和set的红黑树键值是唯一的，不能同时处理，但可以设置辅助键值。 nginx用的也是红黑树



## accep连接队列满了如何处理：

accept返回-1， 并且errno = EFILE 

1：ulimit -n修改系统文件描述符的限制。

2：通过设置一个空文件描述符，每次来了的时候关闭这个空fd，接受一个连接，关闭这个连接，再次打开一个空fd，这样就能处理掉请求连接的信息，如果不这样的话，listenfd的可读事件就会被一直触发。

3：自己限制连接数



## udp问题：

- 滑动窗口是**接受数据端使用的窗口大小**，用来告知发送端接收端的缓存大小，以此可以控制发送端发送数据的大小，从而达到流量控制的目的。
- 拥塞窗口是数据的发送端，拥塞窗口不代表缓存，拥塞窗口指**某一源端数据流在一个RTT内可以最多发送数据包**

dns，么必要用tcp那么麻烦的三次握手四次挥手，就算失败，设置一个定时器，重传就是了

对比tcp优点：重传策略灵活，对于tcp，，由内核协议栈实现，而udp重传策略比较灵活，可以在应用层把tcp的这些特性都实现，tcp升级难度大，也可以理解为，如果修改了tcp的策略，它是对所有应用都会生效，而udp的应用层封装可以根据应用的不同进行更新。

### QUIC

分析对于TCP存在的问题：

1. 升级难，完全由内核实现，比如对于重传策略，udp就能在应用层更灵活的设置，但tcp不行，完全使用了内核实现的策略。
2. tcp建立/断开连接的消耗延迟
3. tcp存在队头阻塞的问题(包括发送端队头阻塞， 接收端队头阻塞)
4. 网络迁移需要重新建立tcp连接
5. tcp是顺序确认，但QUIC支持乱序确认，比如发送了1,2,3,4,5 对于3丢失了可以直接确认5，如果此时3超时，再将3编号为6重发(**通过 Stream ID + Offset 字段信息实现数据的有序性**),就可以辨别出这个6就是需要的数据3.。 而对于ack是顺序确认的，就算服务器收到了，4，5，对也只会回复ACK3， 所有客户端并不知道，对于客户端依然有可能重新发送4，5。

解决方案：

2：对于QUIC而言，因为是基于UDP的，所以无需建立/断开连接的消耗；

3：对于队头阻塞问题，这里就要涉及到http/2的使用，抽象了stream的概念，实现了http**并发传输**(并发发送多个http请求)，一个stream就代表http/1.1里的请求和响应，每个帧的头部会携带stream ID以及offset偏移量信息，所以接收端可以根据这些信息有序组装，但是由于http/2多个stream请求都是在同一条TCP连接上传输，这就意味着多个stream共用一个滑动窗口，因为只有一个滑动窗口，所以会出现TCP层队头阻塞问题，而对于QUIC协议，它借鉴了http/2中stream的概念，但是QUIC给每一个stream都分配了一个独立的滑动窗口，这样使得一个连接上的多个stream没有依赖关系，各自控制各自的滑动窗口，StreamA被阻塞后，不影响streamB,streamC的读取，而对于http/2,所有stream都在一条TCP连接上，streamA阻塞后，streamB，streamC必须阻塞

4：比如从5g变到了wifi，由于QUIC具有连接ID，可以通过这个连接ID来标记通信的两个端点，即使ip地址变化，只要仍保存有上下文信息(比如连接ID，TLS密钥),就可以无缝复用原连接，没有丝毫卡断感，而对于TCP,需要重新建立建议，包括TCP三次握手，TLS四次握手的时延，以及tcp是慢启动的一种方式，给用户的感觉就是网络突然卡顿了

#### quic补充

**RTT计算的歧义：**
quic报文中的packet number是严格单调递增的，即使是重传报文，也同样递增，这样就能避免tcp中出现的**RTT计算的歧义**(TCP中的RTO是基于RTT计算的)，因为tcp中的重传报文序号不会递增，还是原来那个序号。

**QUIC支持乱序确认：**
上边这样做还有一个好处，不再像TCP那样必须有序确认(即3，4，5到了，到2没到，回复给发送端的ack就会一直是2，当2到了，直接回复5，也就是就这回复值ack表明前边的数据一定是到达了的，并且2对应2，3对应3，序号与ack号是对应的)，QUIC**支持乱序确认**(比如发送了3，4，5 ，过程中4，5顺利到达接收端，3丢失了，超时重传，但此时会把3编号为6，因为packet number严格递增，此时接收端接收6，但接收端知道这是3的数据，那么这是怎么做到的呢？因为每个包都包含了它对应的stream字段以及偏移量offset字段，通过它们就能确定这是哪一个包了)。

**quic的流量控制：**
通过window_update帧告诉对端自己可以接收的字节数，这样发送方就不会发送超过这个数量的数据。
通过BlockFrame告诉对端由于流量控制被阻塞了，无法继续发送数据。
quic实现了两种级别的流量控制，stream级别和connect级别(所有stream和起来的概念)，一般讨论stream级别即可。
因为udp没有实现流量控制，所有quic自己实现。当接收窗口成功接收到**连续**的一半接收窗口的大小的数据时，最大接收窗口向右移动，同时向对端发送窗口更新帧，当发送方收到接收方的窗口更新帧后，发送窗口的有边界也会往右扩展，以此达到窗口滑动的效果。
但如果没有达到连续的一半接收窗口的大小时，那么接收窗口还是无法滑动，但这只影响一个stream。

**quic的拥塞控制**
跟tcp差不多，可以说照搬，但是由于quic的拥塞控制的实现是在应用层，对于不同的应用可以灵活的调整拥塞控制策略

**quic可以更快的建立连接**
quic首次连接需要1RTT，服务器通过CA证书私钥加密后，返回给客服端保存起来。下一次再连接时只需要0RTT，
简单来说，通过diffie-hellman算法来进行密钥的交换，可以通过该算法在双方互不知情的情况下建立加密通信，而对于普通的http/2协议，需要进行tcp握手以及tls握手，至少需要2.5RTT,虽然http/2是多路复用技术，但如果出现队头阻塞，效率可能还没http1高





### KCP

比如kcp，它是一个纯算法实现，相对于TCP，KCP以浪费10%-20%的带宽，换取比TCP快30%-40%的传输速度，并且最大延迟降低3倍的传输效果。
特性：

- RTO翻倍与不翻倍
  对于TCP超时重传时间是RTO*2,如果连续丢3次就变成RTO * 8了，而KCP是*1.5(实践证明这个更好)，提高了传输速度
- 拥塞控制方面
  KCP的优势在于可以完全关闭拥塞控制，非常自私的进行发送，但可能造成更为拥堵的情况。TCP大公无私，经常牺牲自己来减少网络拥塞，考虑大局。
- 快在哪里
  没有使用任何系统调用接口，完全是用户层实现，无需建立/关闭连接。很多影响速度的参数都可配(RTO等)。

![1664456986316](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\1664456986316.png)

![1664457144073](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\1664457144073.png)

![1669087655015](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\1669087655015.png)

![1669089123061](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\1669089123061.png)

![这里写图片描述](https://img-blog.csdn.net/20180520115026701?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0MDIxOTIw/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

##  ## 设计者模式

比如c++中pthread_create()，第三个参数必须传静态函数，若要在一个静态函数中使用类的动态成员(包括成员函数和成员变量)，，
可以通过两种方式实现，1：单例模式，类的全局唯一实例来访问动态成员。2：将类的对象(第四个参数，传this)传递给该静态函数。 



## 分布式锁

当获取锁失败，如何判断是否能再次去获得锁？

1. 轮询(mysql中就是这样)
2. 广播通知所有等待的人(redis中， 通过发布订阅模型)

这两种都是非公平锁， 类比单进程多线程中的自旋锁

​	3. 通知具体的某个等待者，(etcd 中就是这样)，这种是公平锁 类别单进程多线程中的互斥锁



## UUID  与 自增ID 区别

关系型数据库中的主键

~~~
为了唯一标识表中的一行数据需要主键，为了使多个表关联起来需要使用外键，为了与业务解耦，需要采用与业务无关的值作为主键。
~~~



    对于查询：
    自增ID是有序的，而UUID是随机的。如果主键是有序的，数据库可以具有更好的查询性能（比如where id < ...），若主键乱序，这样的sql语句进行查找的时候会产生大量IO操作， 影响性能。
    
    对于插入：
    Mysql中B+树一页是16K，若键值是乱序的，会出现很多分页的操作， 产生碎片，开销更大。
    使用主键自增，每次插入一条新的记录，记录就会沿着当前索引节点的后续位置，当一页写满，就会开辟一个新的页
    减少了叶分裂和碎片的产生


​    
​    自增ID所需的存储空间比UUID要小
​    由于自增ID比UUID更加简单，因此生成自增ID的生成速度也比UUID更快
​    自增ID与数据相关，主键会暴露出去的话，自增ID会显示当前表中的数据规模；而UUID则无此风险
​    自增ID在不同的数据库中可能重复，在分布式的环境下无法保证唯一。而UUID在分布式环境下也可以保证唯一

具体而已，自增ID在性能上更有优势，而UUID则更加适应分布式场景



1.因为fd是非阻塞， connect不一定是成功，可以给listenfd绑定一个写事件(因为写事件一直会触发)，通过getsockopt(m_socket, SOL_SOCKET, SO_ERROR, (void*)&error, &len);来获取error指，若为0，则表示成功连接，反之失败。

2.内存池设计

~~~
1.由整块散成小块
伙伴算法(回收的时候麻烦，需要连续的才能合并回收，就像2048游戏)；
就由一个4k的内存块分配，比如分配一个8bit那么就拆分成
2k+1k+512+256+128+64+32+16+8若干小块，回收的时候就合并小块为大块
分配的时候由大块->小块，回收的时候由小块->大块
回收条件，两者一样大，并且相邻

2.一开始划分好若干的小块
slab算法(由小块聚集在一起)


3.在特定业务场景里面
比如在即时通讯中，当有一个连接到来时，就分配一个内存池，当连接断开，就一次性释放，这样就灵活多了


接触陌生的服务，htop虚拟内存在涨
1.内存池有没有泄露，增加打印信息判断是哪里的问题
2.第三方库的内存泄露
~~~

### 大数问题

2G内存在20亿个整数出现次数最多的数

1.map， 2，unordered_map 3，分治







### 僵尸进程

wait 是阻塞的，直到某个进程结束运行为止，结束运行的子进程的PID

waitpid是非阻塞的，但它需要捕获一个已经终止的子进程，但我们并不知道一个子进程是否已经终止了。

SIGCHLD： 当一个子进程结束会发送这个命令给父进程， 在信号处理函数里面调用waitpid





