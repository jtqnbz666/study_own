watch -n 0.5 tree  监视tree命令，每0.5秒刷新一下

wc -l 统计结果行数

奇怪的配置保存方法

~~~
control+o保存再control+x退出
~~~

密钥配置

~~~
密钥配置：ssh-keygen -t rsa 一路回车， 在~/.ssh下id_rsa.pub是公钥文件，id_rsa是私钥文件， 把自己的公钥拷贝到远端的~/.ssh 中的authorized_keys文件(没有就创建)
~~~

杀死某个进程比如nginx

~~~shell
pidof nginx # 可以看到nginx有哪些进程
kill -USR2 $(pidof nginx)
~~~

常用设置tab间距方法

~~~shell
编辑 ~/.vimrc
set tabstop=4			# tab键
set shiftwidth=4 	# 缩进
set expandtab 		# 将制表符替换为等价的空格

# 小tips:也可以直接编辑器输入以下内容
:set tabstop = M 那么一个缩进TAB的作用就是M个空格
~~~

配合管道操作mysql/redis等

~~~shell
echo 'keys *' | docker exec -i data-redis redis-cli #注意不是-it

以下是一个删除指定redis数据的方法
echo 'SCAN 0 MATCH AIMirror_KnockoutPool* COUNT 10000' | redis-online-mirror > AIMirror_KnockoutPool.txt

cat AIMirror_KnockoutPool.txt | awk '{print "UNLINK " $0}' | redis-online-mirror
~~~

nslookup：

~~~
用于查询域名系统（DNS）的记录。它允许用户输入一个域名，并返回与该域名相关的IP地址、域名服务器等信息
~~~

给linux的操作取别名

~~~shell
~/.bashrc文件修改
alias mysql-online='mysql -uroot -p -hrm-bp1c4m1w22oq77q82.rwlb.rds.aliyuncs.com'
那么直接使用 mysql-online就能连接上数据库了

如果使用了fish的话， 需要把这些alias放到~/.config/fish/config.fish文件中
~~~

查看大文件日志(找标志物，比如开头的时间是数字方便做比较)（小时，分钟区分

~~~
开头时间格式为: 2024-01-02T05:47:00+00:00
-F"[T:]"表示以T和:作为分割符
看3-4点
tac logfile.log | awk -F"[T:]" '$2>=3 && $2<=4'

看4.20-4.30
awk -F"[T:]" '$2==4 && $3>=20 && $3<=30' logfile.log

// 看这一分钟(5.47-5.48)的日志
tac data.20240102.log | awk -F"[T:]" '$2==5 && $3>=47 && $3<=48' > testa.log
~~~

cat

~~~
对于较小的文件，tac和cat命令将文件内容加载到内存中。但是对于较大的文件，它们使用的是一种称为“覆盖式磁盘写入”的技术，它们不会将整个文件加载到内存中进行处理
~~~

tar 

~~~
-z 表示使用 gzip 压缩格式。
-c 表示创建新的 tar 存档。
-v 表示在终端显示压缩的过程，以便查看详细信息。
-x 用于解压缩
-f 用于指定要操作的文件。
解压:tar -zxvf 
压缩文件:tar -zcvf myfiles.tar.gz myfile1.txt myfile2.png
以上命令将创建名为 myfiles.tar.gz 的压缩文件，其中包含 myfile1.txt 和 myfile2.png 两个文件。
~~~

sort

~~~
字段号从1开始, ::1:2 这里面的1就是第三个字段
sort -k 4 表示指定以第四个字段来排序，默认第一个字段

sort -t ":" 表示以'-t'分割字段，默认以tab分割，不是空格

sort -n 以数字大小排序，而不是字典序，默认是字典序

sort - r 表示逆序排序， 

比如数据是
qwqee
niha2
1qwe

sort -n 结果如下
niha2
qwqee
1qwe

而直接sort结果如下
1qwe
niha2
qwqee
~~~

uniq 

~~~
因为uniq会考虑连续与不连续的问题，所以一般与sort一起使用
一般是 sort | uniq -c

-c	统计 连续 重复的行出现的次数，并且删除重复的行
123
12341
123
123
sort -c 结果为
1 123
1 12341
2 123


-u 显示出现一次(即不连续重复)的行，不会全局考虑，也就是不管以前出现过没有
比如原数据为
123
123
123142
123
123
123142
sort -u 结果为
123142
123142

但如果原数据为
123
123142
123
123
sort -u 结果为
123
123142


-d 仅显式连续出现的行
123
123
1234123
123
123
sort -d 结果为
123
123


~~~

tr命令

~~~
tr 一般后边跟两个字符集 ，用单引号双引号都可以
默认是-t参数，也就是将字符集1转化为字符集2

1.小写转大写
echo abc | tr 'a-z' 'A-Z' //ABC
echo "thirrrr is firhhhht" | tr  'rh' 'sa' //taissss is fisaaaat
可以看出转换关系是一一对应的
2.将a 转化为 A
echo abc | tr 'a' 'A'  //Abc

-s 将重复出现的字符串压缩为一个字符
1.去除空白行
cat file | tr -s '\n'
也可以用grep -v  "^$"
2.将重复出现的字符压缩并且替换为指定字符
echo "thirrrr is firhhhht" | tr -s "rh" "s"  //this is fist
//这个需要注意它把rhhhh当成一个整体转化为一个s

echo "thirrrr is firhhhht" | tr -s "rh" // thir is firht
~~~

cut

~~~
cut -b 以字节为单位进行分割，仅显示行中指定直接范围的内容
cut -d 自定义分隔符，默认以tab分隔,不是空格，必须配合-f或其他,不能单独存在
cut -fn 表示或者分割后的第n部分内容。 下标从1开始
cut --output-delimiter=' ' 更改输出内容的分隔符
cut --complement

要注意-d并不是把原字符串拆分了， 只是提供给用户一个访问某个字段的方法，原字符串本身没有变化(指的分隔符: 并没有被删除)
比如 "a:b:c:d:e:g:h:i"
cut -d ":" -f1  //a 
cut -d ":" -f 1-4,6,7 //a:b:c:d:g:h 逗号中间不要留空格

把这个分隔符: 变换为自定义的输出，比如 空格
cut -d ":" -f 1-4,6,7 cut --output-delimiter=' '

排除指定字段
cut -d ":" --complement -f 1-4,6,7  //e:i

截取字符串
i = 13145
echo $i | cut -b 3-6 //145 下标从1开始
expr substr $i 3 3	//145 下标从1开始
~~~

split

~~~shell
文件拆分
-l 以行数拆分
-b 以大小拆分

split -l 10 原始文件 拆分后文件的前缀
拆分后原文件会保留。

# 以大小分割
nohup split -b 1048576k -d data.20240101.log 20240101/ &
#nohup表示忽略sigint信号，使用&符号可以将命令放置在后台运行,20240101/表示切割后的文件放到这个目录下
ps -aux | grep "split"找到他可以kill掉

# 以时间段
比如日志格式为，2024-01-04T10:44:13+08:00
mkdir 20240103
awk -F'T' '{print >> ("20240103/data."$1"-"substr($2,0,2)".log")}' data.20240101.log
~~~



### 小技巧

~~~shell
echo test | base64 编码
echo dGVzdAo= | base64 -D 解码
echo -n "xx" | md5sum
echo -n "xx" | sha1sum

如果遇到无法修改/bin下的文件，就修改环境变量，比如mac中就是在～/.zshrc文件中(如果是在bash那么就是~/.bashrc)修改一下环境变量，这样就不用强制一定去/bin下找了，比如
export PATH=$HOME/bin:/usr/local/bin:$PATH:/opt/homebrew/bin

vim中set list 显示不可见字符， set nu 显示行号

docker logs的时候加个-f 持续看输出内容

在etc/profile 修改配置，就是永久有效的

gunzip 文件  解压.gz文件

进程三件套：
ps -aux | grep _ser  通过部分名字查看进程信息，-aux 比 -ef 信息详细
ps -p 11361 -o comm= 通过进程号查看进程名
lsof -i:3306		通过端口号查看进程信息。

程序编译三件套 -I, -L, -l 分别表示头文件路径，链接库的路径， -l 指定链接的库，如果是动态库的话要放到/lib;/usr/lib/; usr/local/lib，如果没放有三种方式
1：加上-Wl,-rpath=指定动态库链接路径 
 g++ test.cpp -L. -ladd -Wl,-rpath=.
 
当动态库为libxx-x.x.x.so之类的，给他弄个软连接
ln  -s  libxx-x.x.x.so  libxx.so 

2:去/etc/ld.so.conf文件中加上你想要的路径，保存后执行ldconfig命令即可

3.export LD_LIBRARY_PATH=.:$LD_LIBRARY_PATH 那个点就是你想要指定的路径， 但linux子系统好像并不支持这样操作。

ldd (list, dynamic, dependencies)可以查看可执行文件依赖的动态库，也可以查看动态库依赖的其他动态库，如果 ldd 静态库 会告诉你 not a dynamic executable


全选vim， v + gg + G
复制全部  ggyG
删除全部  ggdG

移动行首 home , 行尾 end

查看ubuntu版本  cat /etc/issue
制表符\t 会自动帮你控制距离

echo -e "test\ntest" // 表示将\n转义字符输出，默认不输出
echo -ne "test" //-n表示输出之后不换行，默认是换行的

 netstat  通过端口号查一些信息，或者服务名查端口号
grep -
lsof -i:4369  通过端口查看这个进程的相关信息 
nc -l 4369 开启一个端口号

ps -aux | wc -l  统计进程数量

默认的>是只管stdout
2> 表示只管stderr , 2>> 表示只管stderr同时追加写。
命令 > 文件 2>&1  //将stdout和stderr覆盖的方式定向到文件， 把第一个>改为>>则表示追加(不要改第二个>)， 可重定向到/dev/null丢弃打印内容

~~~







**linux三剑客** awk(利用正则做一些操作，比如得到数据的第几列)  grep(查询文本信息) sed(替换文本信息)

~~~shell
（文本统计）
b.txt 内容
http://www.baidu.com/index.html
https://www.atguigu.com/index.html
http://www.sina.com.cn/1024.html
https://www.atguigu.com/2048.html
http://www.sina.com.cn/4096.html
https://www.atguigu.com/8192.html



cat b.txt | cut -d '/' -f3 | sort | uniq -c | sort -nr
# cut -d "/" -f3  用"/"作为分隔符，截取第个3字段
# sort 第一次排序
# uniq -c 显示该行重复次数
# sort -nr 按照数值(n)从大到小排(r逆序)

最终结果
3 www.atguigu.com
2 www.sina.com.cn
1 www. baidu.com


（ ip 连接数统计并排序）
netstat -an | grep ESTABLISHED | awk '{print $5}' | cut -d ":" -f1 | sort -n | uniq -c | sort -nr
~~~



awk

~~~shell
test.txt内容, 124为空行
1  
2
3  ilovehh
4
5  you support

打印test.txt文件内容的每一行的最后一个字符串，如果只有一个字符串，那么就直接打印出来
awk '{print $NF}' test.txt # ${NF-1}则是倒数第二个
#ilovehh 
#support

输出每行数据的列数 
awk '{print NF}' # 0 0 1 0 3 每行一个数字

输出每行数据的行号
awk '{print NR}' # 1 2 3 4 5 每行一个数字

打印每行全部内容 
awk '{print $0}' #'{print $1}'每行第一列内容

定义变量
awk -v x="jt" -v y=666 '{print x, y}'


常用命令
cat test.txt | awk 'NF%2==0' #过滤掉奇数行


~~~

sed

~~~
查看文件的指定中间行

sed -n '5,10p' filename #这样你就可以只查看文件的第5行到第10行。


cat test | tail -n 10 | head -n 5  显示test文件的第5~9行

tail -n 10  #显示最后10行

tail -n +10 #从10行开始显示，显示10行以后的

head -n 10  #显示前面10行

// 动态查看文件内容
tail -n 10 -f data.log | grep RankBoardService
~~~

grep

~~~shell
-i：忽略大小写，使搜索不区分大小写。
-v：反向匹配模式，只显示不匹配的行。
-n 或 --line-number：输出匹配行的行号。
-c 或 --count：只输出匹配的行数而不显示匹配的内容。
-r 或 --recursive：递归搜索目录及其子目录下的文件。
-l 只列出包含搜索内容的文件名
-E  使用更强大的基于正则表达式的模式匹配引擎，支持更多的正则表达式
-w 表示查找包含整个单词的行
一般可配合 wc -l 进行匹配行数统计
搜索不包含以下任一字段的内容 grep -vE 'SelectHero|InBattle|IsMatching|WaitingForPreparation|InTeam|Watching|InAdventureBattle'   不要-v就是包含任一字段的意思



举例:
1.使用 -r 搜索多个文件
grep -r "jiangtao" . (这样就可以grep多个文件了)
结果：./tt2:jiangtao， 左边是文件名，右边是内容
2.-r 和 -E配合
grep -rE ""jiangtao"|"test"" . #表示递归搜索当前文件夹下所有文件， 筛选出所有包含jiangtao或test的行 // "jiangtao|test"也行
如果查询的内容中含有|等特殊符号，需要使用转义字符, 例如查询"jiangtao|"
grep -rE "jiangtao\||test" .
3.-r 和 -l配合
grep -rl "jiangtao" .
结果:	./tt2



~~~

scp命令

```
scp * -r ubuntu@49.234.61.220:/home/ubuntu .
```

静态库编译：

```c
g++ -c add.cpp
ar rcs libadd.a add.o 
//不能把add.o 和 libadd.a交换位置, 不能ar rcs add.o -o libadd.a
g++ main -L. -ladd
```

动态库编译

可以扯一点gcc 和 g++的关系

```C
g++ -fPIC -shared add.cpp -o libadd.so
cp libadd.so /usr/lib
g++ main -L. -ladd

//把上边的g++换成gcc也可以
```



多线程gdb调试

```c
b ：break 断点
方式1： b + 行号，方式2 b + 函数名
方式3: 若需要断点的地方不在主源文件，而在某个其他源文件中， 比如需要在其他源文件的 void test(int a);
这一行断点， 则直接 b void test(int )即可(我发现含有IM::BaseDefine等作用域参数的函数不能使用这个方法)
方式4：同样是在其他文件中， b test.cpp:22   即表示在test.cpp中22行断点

d ： disable  清除断点 
d + 具体断点数字

c : continue
继续执行， 直到遇到阻塞(比如cin >>) 或者下一个断点

r : run
一般刚调试时，需要先设置好断点， 然后 r 表示运行程序

n ：一行一行执行
s : 一行一行执行，但若是一个函数，会进入这个函数

p : print 打印	
p + 具体的变量		//可以看到打印出类的private 变量

bt ： 查看当前栈的情况

多线程：
info break ：查看断点情况
info thread : 查看有哪些线程
thread + 数字 : 表示进入某个线程
thread apply 数字 命令 : 如 thread apply 2 n  
表示线程2中，执行下一行， 如果你直接n ，则当前你在哪个线程就执行哪个线程的下一行。

set scheduler-locking off : 运行全部线程
set scheduler-locking on : 只运行当前线程
因为很多线程同时运行可能不方便查看信息

```

